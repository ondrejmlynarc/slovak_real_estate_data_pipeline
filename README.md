# Real Estate Data Scraper

This Python script utilizes Selenium and BeautifulSoup to scrape real estate data from a specific website in Slovakia. The data is then stored in a CSV file and uploaded to Google Cloud Storage.

## Usage

1. Install the required Python libraries by running:

   ```bash
   pip install selenium beautifulsoup4 tqdm pandas google-cloud-storage
Download the appropriate webdriver for Firefox and set the path in the script:

python
Copy code
webdriver_path = r'C:\path\to\your\webdriver\geckodriver.exe'
Modify the region_website variable to the desired real estate website:

python
Copy code
region_website = 'https://www.nehnutelnosti.sk/bratislava/'
Run the script to initiate the scraping process:

bash
Copy code
python your_script_name.py
Dependencies
selenium
beautifulsoup4
tqdm
pandas
google-cloud-storage
File Naming Convention
The CSV file generated follows the naming convention: region_name_current_date.csv.

Google Cloud Storage Upload
The script uploads the CSV file to a specified Google Cloud Storage bucket (real_estate_scraping). The blob path includes the region and current datetime.

Note: Make sure to secure your Google Cloud Storage credentials for authentication.

Feel free to adjust any details or add more information as needed.

Feel free to explore the visualization of market trends in Slovakia generated by this project: Real Estate Market Trends - Slovakia.
